{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad613df6",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "Kami membagi pekerjaan nomor `1. Modelling` menjadi 4 jenis:\n",
    "1. Logistic Regression menggunakan Data Transformasi Quantile\n",
    "2. Logistic Regression menggunakan Data Transformasi Logaritmik\n",
    "3. Model Lainnya menggunakan Data Transformasi Quantile\n",
    "4. Model Lainnya menggunakan Data Transformasi Logaritmik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dcd8250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'rakamin' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# Run to access the CSV file\n",
    "!git clone https://github.com/refaniefs/rakamin.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74e6303e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in c:\\users\\asus1\\anaconda3\\lib\\site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "# Run to install and import packages\n",
    "!pip install --upgrade xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7faf7ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20971a56",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5b37b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(clf, pred, xtrain, ytrain, xtest, ytest, ypredproba, ypredtrainproba):\n",
    "    print(\"Score: \", round(clf.score(xtest, ytest),4))\n",
    "    print(\"Accuracy (Test Set): \", round(accuracy_score(ytest, pred),4))\n",
    "    print(\"Precision (Test Set): \", round(precision_score(ytest, pred),4))\n",
    "    print(\"Recall (Test Set): \", round(recall_score(ytest, pred),4))\n",
    "    print(\"F1-Score (Test Set): \", round(f1_score(ytest, pred),4))\n",
    "    print('roc-auc (test-proba): ', round(roc_auc_score(ytest, ypredproba[:,1]),4))\n",
    "    print('roc-auc (train-proba): ', round(roc_auc_score(ytrain, ypredtrainproba[:,1]),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13795eaf",
   "metadata": {},
   "source": [
    "## Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e431280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_importance</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Reached.on.Time_Y.N</th>\n",
       "      <th>Cost_of_the_Product_tr</th>\n",
       "      <th>Discount_offered_tr</th>\n",
       "      <th>Weight_in_gms_tr</th>\n",
       "      <th>Prior_purchases_tr</th>\n",
       "      <th>prior_purchase_std</th>\n",
       "      <th>product_cost_norm</th>\n",
       "      <th>discount_norm</th>\n",
       "      <th>...</th>\n",
       "      <th>Warehouse_block_B</th>\n",
       "      <th>Warehouse_block_C</th>\n",
       "      <th>Warehouse_block_D</th>\n",
       "      <th>Warehouse_block_F</th>\n",
       "      <th>Mode_of_Shipment_Flight</th>\n",
       "      <th>Mode_of_Shipment_Road</th>\n",
       "      <th>Mode_of_Shipment_Ship</th>\n",
       "      <th>Cost_Per_Weight</th>\n",
       "      <th>Cost_After_Disc</th>\n",
       "      <th>Weight_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.378114</td>\n",
       "      <td>0.365531</td>\n",
       "      <td>0.634479</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-1.323289</td>\n",
       "      <td>0.210280</td>\n",
       "      <td>0.526359</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028200</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.304121</td>\n",
       "      <td>-0.017565</td>\n",
       "      <td>0.387078</td>\n",
       "      <td>-0.211070</td>\n",
       "      <td>-0.255579</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.466155</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.057569</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9486</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.689670</td>\n",
       "      <td>-1.207532</td>\n",
       "      <td>1.803394</td>\n",
       "      <td>1.037937</td>\n",
       "      <td>1.089577</td>\n",
       "      <td>0.177570</td>\n",
       "      <td>0.166048</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022847</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6599</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.149853</td>\n",
       "      <td>-0.875354</td>\n",
       "      <td>0.033880</td>\n",
       "      <td>-0.211070</td>\n",
       "      <td>-0.255579</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.263179</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048379</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.199766</td>\n",
       "      <td>0.746351</td>\n",
       "      <td>-0.866189</td>\n",
       "      <td>0.506348</td>\n",
       "      <td>0.501974</td>\n",
       "      <td>0.238318</td>\n",
       "      <td>0.614449</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.088715</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Product_importance  Gender  Reached.on.Time_Y.N  Cost_of_the_Product_tr  \\\n",
       "6490                   1       0                    0               -1.378114   \n",
       "4788                   2       0                    1                1.304121   \n",
       "9486                   1       1                    1               -1.689670   \n",
       "6599                   1       0                    0               -0.149853   \n",
       "1023                   0       1                    1               -1.199766   \n",
       "\n",
       "      Discount_offered_tr  Weight_in_gms_tr  Prior_purchases_tr  \\\n",
       "6490             0.365531          0.634479           -5.199338   \n",
       "4788            -0.017565          0.387078           -0.211070   \n",
       "9486            -1.207532          1.803394            1.037937   \n",
       "6599            -0.875354          0.033880           -0.211070   \n",
       "1023             0.746351         -0.866189            0.506348   \n",
       "\n",
       "      prior_purchase_std  product_cost_norm  discount_norm  ...  \\\n",
       "6490           -1.323289           0.210280       0.526359  ...   \n",
       "4788           -0.255579           0.813084       0.466155  ...   \n",
       "9486            1.089577           0.177570       0.166048  ...   \n",
       "6599           -0.255579           0.500000       0.263179  ...   \n",
       "1023            0.501974           0.238318       0.614449  ...   \n",
       "\n",
       "      Warehouse_block_B  Warehouse_block_C  Warehouse_block_D  \\\n",
       "6490                  1                  0                  0   \n",
       "4788                  0                  0                  0   \n",
       "9486                  0                  0                  0   \n",
       "6599                  0                  0                  1   \n",
       "1023                  0                  0                  0   \n",
       "\n",
       "      Warehouse_block_F  Mode_of_Shipment_Flight  Mode_of_Shipment_Road  \\\n",
       "6490                  0                        0                      0   \n",
       "4788                  1                        0                      0   \n",
       "9486                  0                        0                      0   \n",
       "6599                  0                        1                      0   \n",
       "1023                  0                        0                      0   \n",
       "\n",
       "      Mode_of_Shipment_Ship  Cost_Per_Weight  Cost_After_Disc  Weight_level  \n",
       "6490                      1         0.028200              132             1  \n",
       "4788                      1         0.057569              263             1  \n",
       "9486                      1         0.022847              132             2  \n",
       "6599                      0         0.048379              200             1  \n",
       "1023                      1         0.088715              134             0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('shipping_fix.csv')\n",
    "\n",
    "# use this instead if using google colab:\n",
    "# df = pd.read_csv('/rakamin/final-project/shipping_fix.csv')\n",
    "\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9631310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Product_importance', 'Gender', 'Reached.on.Time_Y.N',\n",
       "       'Cost_of_the_Product_tr', 'Discount_offered_tr', 'Weight_in_gms_tr',\n",
       "       'Prior_purchases_tr', 'prior_purchase_std', 'product_cost_norm',\n",
       "       'discount_norm', 'weight_norm', 'Warehouse_block_A',\n",
       "       'Warehouse_block_B', 'Warehouse_block_C', 'Warehouse_block_D',\n",
       "       'Warehouse_block_F', 'Mode_of_Shipment_Flight', 'Mode_of_Shipment_Road',\n",
       "       'Mode_of_Shipment_Ship', 'Cost_Per_Weight', 'Cost_After_Disc',\n",
       "       'Weight_level'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3d54ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pengelompokan kolom berdasarkan jenis preprocessing\n",
    "df_quantile = df.drop(columns = ['product_cost_norm','prior_purchase_std','discount_norm','weight_norm'])\n",
    "\n",
    "df_log = df.drop(columns = ['Cost_of_the_Product_tr','Discount_offered_tr','Weight_in_gms_tr','Prior_purchases_tr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aab3af",
   "metadata": {},
   "source": [
    "# [Soal Nomor 1] Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf55828",
   "metadata": {},
   "source": [
    "# Jenis 1. Logistic Regression with Quantile Trf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e3919df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantile_lr = df_quantile.drop(columns=['Warehouse_block_A','Mode_of_Shipment_Flight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e397dca",
   "metadata": {},
   "source": [
    "## 1A. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2556eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_qlr = df_quantile_lr.drop(columns=['Reached.on.Time_Y.N'])\n",
    "y_qlr = df_quantile_lr[['Reached.on.Time_Y.N']]\n",
    "\n",
    "X_qlr_train, X_qlr_test, y_qlr_train, y_qlr_test = train_test_split(X_qlr, y_qlr, test_size=0.3, random_state=42,stratify=y_qlr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19df53e1",
   "metadata": {},
   "source": [
    "## 1B. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acf7f873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantile_lr = LogisticRegression(random_state=42)\n",
    "\n",
    "quantile_lr.fit(X_qlr_train, y_qlr_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5461d3",
   "metadata": {},
   "source": [
    "## 1C. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c36d2b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.65\n",
      "Accuracy (Test Set):  0.65\n",
      "Precision (Test Set):  0.6952\n",
      "Recall (Test Set):  0.747\n",
      "F1-Score (Test Set):  0.7202\n",
      "roc-auc (test-proba):  0.7241\n",
      "roc-auc (train-proba):  0.7302\n"
     ]
    }
   ],
   "source": [
    "y_qlr_pred = quantile_lr.predict(X_qlr_test)\n",
    "y_qlr_pred_proba = quantile_lr.predict_proba(X_qlr_test)\n",
    "y_qlr_pred_train = quantile_lr.predict(X_qlr_train)\n",
    "y_qlr_pred_train_proba = quantile_lr.predict_proba(X_qlr_train)\n",
    "\n",
    "model_eval(quantile_lr, y_qlr_pred, X_qlr_train, y_qlr_train, X_qlr_test, y_qlr_test, y_qlr_pred_proba, y_qlr_pred_train_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f703b37c",
   "metadata": {},
   "source": [
    "## 1D. Apakah Model Sudah Best-fit?\n",
    "Belum bestfit, score penting dapat ditingkatkan menggunakan hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebdd247",
   "metadata": {},
   "source": [
    "## 1E. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0aa34f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.7247\n",
      "Accuracy (Test Set):  0.6425\n",
      "Precision (Test Set):  0.6881\n",
      "Recall (Test Set):  0.7442\n",
      "F1-Score (Test Set):  0.7151\n",
      "roc-auc (test-proba):  0.7247\n",
      "roc-auc (train-proba):  0.7301\n",
      "      \n",
      "Best penalty : l2\n",
      "Best C : 0.03\n",
      "Best solver : liblinear\n"
     ]
    }
   ],
   "source": [
    "hyperparameterqlr = {'penalty':['l1', 'l2'],\n",
    "                    'C':[0.0001, 0.001, 0.1, 0.02, 0.03, 0.01],\n",
    "                    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "\n",
    "quantile_lr = RandomizedSearchCV(LogisticRegression(random_state=42), hyperparameterqlr, cv=5, scoring='roc_auc')\n",
    "quantile_lr.fit(X_qlr_train, y_qlr_train)\n",
    "\n",
    "y_qlr_pred = quantile_lr.predict(X_qlr_test)\n",
    "y_qlr_pred_proba = quantile_lr.predict_proba(X_qlr_test)\n",
    "y_qlr_pred_train = quantile_lr.predict(X_qlr_train)\n",
    "y_qlr_pred_train_proba = quantile_lr.predict_proba(X_qlr_train)\n",
    "\n",
    "model_eval(quantile_lr, y_qlr_pred, X_qlr_train, y_qlr_train, X_qlr_test, y_qlr_test, y_qlr_pred_proba, y_qlr_pred_train_proba)\n",
    "print('      ')\n",
    "hpqlr = list(hyperparameterqlr)\n",
    "for i in hpqlr:\n",
    "    print('Best',i,':', quantile_lr.best_estimator_.get_params()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5834108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2894705e880>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(quantile_lr, X_qlr_test, y_qlr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf106b2",
   "metadata": {},
   "source": [
    "# Jenis 2. Logistic Regression with Logarithmic Trf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "266253f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log_lr = df_log.drop(columns=['Warehouse_block_A','Mode_of_Shipment_Flight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5928fb6",
   "metadata": {},
   "source": [
    "## 1A. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e459fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_llr = df_log_lr.drop(columns=['Reached.on.Time_Y.N'])\n",
    "y_llr = df_log_lr[['Reached.on.Time_Y.N']]\n",
    "\n",
    "X_llr_train, X_llr_test, y_llr_train, y_llr_test = train_test_split(X_llr, y_llr, test_size=0.3, random_state=42,stratify=y_llr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c667aded",
   "metadata": {},
   "source": [
    "## 1B. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bcb54a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_lr = LogisticRegression(random_state=42)\n",
    "\n",
    "log_lr.fit(X_llr_train, y_llr_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557140b3",
   "metadata": {},
   "source": [
    "## 1C. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e50bd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.6474\n",
      "Accuracy (Test Set):  0.6474\n",
      "Precision (Test Set):  0.7007\n",
      "Recall (Test Set):  0.7245\n",
      "F1-Score (Test Set):  0.7124\n",
      "roc-auc (test-proba):  0.7306\n",
      "roc-auc (train-proba):  0.7355\n"
     ]
    }
   ],
   "source": [
    "y_llr_pred = log_lr.predict(X_llr_test)\n",
    "y_llr_pred_proba = log_lr.predict_proba(X_llr_test)\n",
    "y_llr_pred_train = log_lr.predict(X_llr_train)\n",
    "y_llr_pred_train_proba = log_lr.predict_proba(X_llr_train)\n",
    "\n",
    "model_eval(log_lr, y_llr_pred, X_llr_train, y_llr_train, X_llr_test, y_llr_test, y_llr_pred_proba, y_llr_pred_train_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be8600",
   "metadata": {},
   "source": [
    "## 1D. Apakah Model Sudah Best-fit?\n",
    "Belum bestfit, score penting dapat ditingkatkan menggunakan hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361f21c4",
   "metadata": {},
   "source": [
    "## 1E. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd08960d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.73\n",
      "Accuracy (Test Set):  0.6467\n",
      "Precision (Test Set):  0.6933\n",
      "Recall (Test Set):  0.7426\n",
      "F1-Score (Test Set):  0.7171\n",
      "roc-auc (test-proba):  0.73\n",
      "roc-auc (train-proba):  0.7373\n",
      "      \n",
      "Best penalty : l2\n",
      "Best C : 0.1\n",
      "Best solver : liblinear\n"
     ]
    }
   ],
   "source": [
    "hyperparameterllr = {'penalty':['l1', 'l2'],\n",
    "                    'C':[0.0001, 0.001, 0.1, 0.02, 0.03, 0.01],\n",
    "                    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "\n",
    "log_lr = RandomizedSearchCV(LogisticRegression(random_state=42), hyperparameterllr, cv=5, scoring='roc_auc')\n",
    "log_lr.fit(X_llr_train, y_llr_train)\n",
    "\n",
    "y_llr_pred = log_lr.predict(X_llr_test)\n",
    "y_llr_pred_proba = log_lr.predict_proba(X_llr_test)\n",
    "y_llr_pred_train = log_lr.predict(X_llr_train)\n",
    "y_llr_pred_train_proba = log_lr.predict_proba(X_llr_train)\n",
    "\n",
    "model_eval(log_lr, y_llr_pred, X_llr_train, y_llr_train, X_llr_test, y_llr_test, y_llr_pred_proba, y_llr_pred_train_proba)\n",
    "print('      ')\n",
    "hpllr = list(hyperparameterllr)\n",
    "for i in hpllr:\n",
    "    print('Best',i,':', log_lr.best_estimator_.get_params()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e072aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2894e607b50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(log_lr, X_llr_test, y_llr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b22194",
   "metadata": {},
   "source": [
    "# Jenis 3. Quantile Trf Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701786ab",
   "metadata": {},
   "source": [
    "## 1A. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a1e60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_q = df_quantile.drop(columns=['Reached.on.Time_Y.N'])\n",
    "y_q = df_quantile[['Reached.on.Time_Y.N']]\n",
    "\n",
    "X_q_train, X_q_test, y_q_train, y_q_test = train_test_split(X_q, y_q, test_size=0.3, random_state=42,stratify=y_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a631cb12",
   "metadata": {},
   "source": [
    "## 1B. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "084b763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    # \"Support Vector Machine (RBF Kernel)\": SVC(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"XGboost\": XGBClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ae6af1",
   "metadata": {},
   "source": [
    "## 1C. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18ddc1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors\n",
      "          \n",
      "Score:  0.6395\n",
      "Accuracy (Test Set):  0.6395\n",
      "Precision (Test Set):  0.7139\n",
      "Recall (Test Set):  0.6709\n",
      "F1-Score (Test Set):  0.6917\n",
      "roc-auc (test-proba):  0.6969\n",
      "roc-auc (train-proba):  0.8579\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "Decision Tree\n",
      "          \n",
      "Score:  0.6458\n",
      "Accuracy (Test Set):  0.6458\n",
      "Precision (Test Set):  0.7072\n",
      "Recall (Test Set):  0.7037\n",
      "F1-Score (Test Set):  0.7055\n",
      "roc-auc (test-proba):  0.6307\n",
      "roc-auc (train-proba):  1.0\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "Random Forest\n",
      "          \n",
      "Score:  0.654\n",
      "Accuracy (Test Set):  0.654\n",
      "Precision (Test Set):  0.7529\n",
      "Recall (Test Set):  0.6342\n",
      "F1-Score (Test Set):  0.6885\n",
      "roc-auc (test-proba):  0.7359\n",
      "roc-auc (train-proba):  1.0\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "Gradient Boosting\n",
      "          \n",
      "Score:  0.6758\n",
      "Accuracy (Test Set):  0.6758\n",
      "Precision (Test Set):  0.8505\n",
      "Recall (Test Set):  0.5608\n",
      "F1-Score (Test Set):  0.6759\n",
      "roc-auc (test-proba):  0.7326\n",
      "roc-auc (train-proba):  0.8406\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "Gaussian Naive Bayes\n",
      "          \n",
      "Score:  0.659\n",
      "Accuracy (Test Set):  0.659\n",
      "Precision (Test Set):  0.7638\n",
      "Recall (Test Set):  0.6287\n",
      "F1-Score (Test Set):  0.6897\n",
      "roc-auc (test-proba):  0.7337\n",
      "roc-auc (train-proba):  0.7416\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "AdaBoost\n",
      "          \n",
      "Score:  0.6741\n",
      "Accuracy (Test Set):  0.6741\n",
      "Precision (Test Set):  0.8301\n",
      "Recall (Test Set):  0.5778\n",
      "F1-Score (Test Set):  0.6813\n",
      "roc-auc (test-proba):  0.7377\n",
      "roc-auc (train-proba):  0.7907\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "XGboost\n",
      "          \n",
      "Score:  0.6434\n",
      "Accuracy (Test Set):  0.6434\n",
      "Precision (Test Set):  0.7266\n",
      "Recall (Test Set):  0.655\n",
      "F1-Score (Test Set):  0.6889\n",
      "roc-auc (test-proba):  0.7321\n",
      "roc-auc (train-proba):  0.9832\n",
      "          \n",
      "==========================================================\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(X_q_train, y_q_train)\n",
    "    y_q_pred = model.predict(X_q_test)\n",
    "    y_q_pred_proba = model.predict_proba(X_q_test)\n",
    "    y_q_pred_train = model.predict(X_q_train)\n",
    "    y_q_pred_train_proba = model.predict_proba(X_q_train)\n",
    "    print(name)\n",
    "    print('          ')\n",
    "    model_eval(model, y_q_pred, X_q_train, y_q_train, X_q_test, y_q_test, y_q_pred_proba, y_q_pred_train_proba)\n",
    "    print('          ')\n",
    "    print('==========================================================')\n",
    "    print('          ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a086b25a",
   "metadata": {},
   "source": [
    "## 1D. Apakah Model Sudah Best-fit?\n",
    "Belum bestfit, score penting dapat ditingkatkan menggunakan hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e80896",
   "metadata": {},
   "source": [
    "## 1E. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28168a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression Hyperparameter Tuning\n",
    "hyperparameterlr = {'penalty' : ['l1', 'l2'],\n",
    "                    'C' : [0.0001, 0.001, 0.1, 0.02, 0.03, 0.01], \n",
    "                    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "                   }\n",
    "\n",
    "# DesicionTree Hyperparameter Tuning\n",
    "hyperparameterdt = {'max_depth' : [int(x) for x in np.linspace(1, 100, num = 30)], # Maximum number of levels in tree, \n",
    "                    'min_samples_split' : [2, 5, 10, 100], # Minimum number of samples required to split a node, \n",
    "                    'min_samples_leaf' : [1, 2, 4, 10, 20, 50], # Minimum number of samples required at each leaf node,\n",
    "                    'max_features' : ['auto', 'sqrt','log2'] # Number of features to consider at every split\n",
    "                    }\n",
    "\n",
    "# RandomForest Hyperparameter Tuning\n",
    "hyperparameterrf = {'n_estimators' : [int(x) for x in np.linspace(1, 10, num = 10)],\n",
    "                    'max_depth' : [int(x) for x in np.linspace(1, 10, num = 3)], # Maximum number of levels in tree\n",
    "                    'min_samples_split' : [int(x) for x in np.linspace(1, 40, num = 30)], # Minimum number of samples required to split a node\n",
    "                    'min_samples_leaf' : [int(x) for x in np.linspace(1, 20, num = 30)], # Minimum number of samples required at each leaf node\n",
    "                    'max_features' : ['auto', 'sqrt','log2'], # Number of features to consider at every split\n",
    "                    'criterion' : ['gini', 'entropy']\n",
    "                   }\n",
    "\n",
    "# K-Nearest Neighbors Hyperparameter Tuning]\n",
    "hyperparameterkn = {'leaf_size' : list(range(1,50)),\n",
    "                    'n_neighbors' : list(range(1,30)),\n",
    "                    'p' : [1,2]\n",
    "                   }\n",
    "\n",
    "# Gaussian Naive Bayes Hyperparameter Tuning\n",
    "hyperparameterNB = {'var_smoothing' : [int(x) for x in np.linspace(0,100, num=10)] \n",
    "                   }\n",
    "\n",
    "# Gradient Boosting hyperparameter Tuning\n",
    "hyperparametergb = {'n_estimators' : [2,6,8,10],\n",
    "                    'max_depth' : [int(x) for x in np.linspace(1, 100, num = 5)], # Maximum number of levels in tree\n",
    "                    'learning_rate' : [0.01,0.1,1,10]\n",
    "                   }\n",
    "\n",
    "# # Adaboost hyperparameter Tuning\n",
    "# n_estimators = [int(x) for x in np.linspace(100, 2000, 1000)],\n",
    "# learning_rate = [float(x) for x in np.linspace(0.001, 0.1, 100)],\n",
    "# algorithm = ['SAMME', 'SAMME.R']\n",
    "# hyperparameterab = dict(\n",
    "#                         n_estimators = n_estimators,\n",
    "#                         algorithm = algorithm, \n",
    "#                         learning_rate = learning_rate \n",
    "#                         )\n",
    "\n",
    "# XGBoost hyperparameter Tuning\n",
    "hyperparameterxgb = {'max_depth' : [int(x) for x in np.linspace(10, 50, 10)],\n",
    "                    'min_child_weight' : [int(x) for x in np.linspace(1, 10, 11)],\n",
    "                    'gamma' : [float(x) for x in np.linspace(0, 1, 11)],\n",
    "                    'tree_method' : ['auto', 'exact', 'approx', 'hist'],\n",
    "                    'colsample_bytree' : [float(x) for x in np.linspace(0, 1, 11)],\n",
    "                    'learning_rate' : [float(x) for x in np.linspace(0, 1, 100)],\n",
    "                    'reg_lambda' : [float(x) for x in np.linspace(0, 1, 11)],\n",
    "                    'reg_alpha' : [float(x) for x in np.linspace(0, 1, 11)],\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63c1a507",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"K-Nearest Neighbors tuned\": RandomizedSearchCV(KNeighborsClassifier(), hyperparameterkn, cv=5, scoring='roc_auc'),\n",
    "    \"Decision Tree tuned\": RandomizedSearchCV(DecisionTreeClassifier(random_state = 42), hyperparameterdt, cv=5, scoring='roc_auc'),\n",
    "    # \"Support Vector Machine (RBF Kernel)\": SVC(),\n",
    "    \"Random Forest tuned\": RandomizedSearchCV(RandomForestClassifier(random_state = 42), hyperparameterrf, cv=5, scoring='roc_auc'),\n",
    "    \"Gradient Boosting tuned\": RandomizedSearchCV(GradientBoostingClassifier(random_state = 42), hyperparametergb, cv=5, scoring='roc_auc'),\n",
    "    \"Gaussian Naive Bayes tuned\": RandomizedSearchCV(GaussianNB(), hyperparameterNB, cv=5, verbose=1, scoring='roc_auc'),\n",
    "    # \"AdaBoost tuned\": RandomizedSearchCV(AdaBoostClassifier(random_state = 42), hyperparametergb, cv=5, scoring='roc_auc'),\n",
    "    \"XGboost tuned\": RandomizedSearchCV(XGBClassifier(random_state = 42), hyperparametergb, cv=5, scoring='roc_auc')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0be644eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors tuned\n",
      "          \n",
      "Score:  0.7191\n",
      "Accuracy (Test Set):  0.6431\n",
      "Precision (Test Set):  0.7365\n",
      "Recall (Test Set):  0.6353\n",
      "F1-Score (Test Set):  0.6822\n",
      "roc-auc (test-proba):  0.7191\n",
      "roc-auc (train-proba):  0.7927\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "Decision Tree tuned\n",
      "          \n",
      "Score:  0.7383\n",
      "Accuracy (Test Set):  0.65\n",
      "Precision (Test Set):  0.7415\n",
      "Recall (Test Set):  0.644\n",
      "F1-Score (Test Set):  0.6893\n",
      "roc-auc (test-proba):  0.7383\n",
      "roc-auc (train-proba):  0.829\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "Random Forest tuned\n",
      "          \n",
      "Score:  0.7409\n",
      "Accuracy (Test Set):  0.6728\n",
      "Precision (Test Set):  0.818\n",
      "Recall (Test Set):  0.5882\n",
      "F1-Score (Test Set):  0.6843\n",
      "roc-auc (test-proba):  0.7409\n",
      "roc-auc (train-proba):  0.8393\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "Gradient Boosting tuned\n",
      "          \n",
      "Score:  0.7369\n",
      "Accuracy (Test Set):  0.6028\n",
      "Precision (Test Set):  0.6028\n",
      "Recall (Test Set):  1.0\n",
      "F1-Score (Test Set):  0.7522\n",
      "roc-auc (test-proba):  0.7369\n",
      "roc-auc (train-proba):  0.7468\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Gaussian Naive Bayes tuned\n",
      "          \n",
      "Score:  0.7337\n",
      "Accuracy (Test Set):  0.6586\n",
      "Precision (Test Set):  0.7636\n",
      "Recall (Test Set):  0.6281\n",
      "F1-Score (Test Set):  0.6893\n",
      "roc-auc (test-proba):  0.7337\n",
      "roc-auc (train-proba):  0.7416\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "XGboost tuned\n",
      "          \n",
      "Score:  0.7318\n",
      "Accuracy (Test Set):  0.6471\n",
      "Precision (Test Set):  0.7241\n",
      "Recall (Test Set):  0.6698\n",
      "F1-Score (Test Set):  0.6959\n",
      "roc-auc (test-proba):  0.7318\n",
      "roc-auc (train-proba):  0.9572\n",
      "          \n",
      "==========================================================\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(X_q_train, y_q_train)\n",
    "    y_q_pred = model.predict(X_q_test)\n",
    "    y_q_pred_proba = model.predict_proba(X_q_test)\n",
    "    y_q_pred_train = model.predict(X_q_train)\n",
    "    y_q_pred_train_proba = model.predict_proba(X_q_train)\n",
    "    print(name)\n",
    "    print('          ')\n",
    "    model_eval(model, y_q_pred, X_q_train, y_q_train, X_q_test, y_q_test, y_q_pred_proba, y_q_pred_train_proba)\n",
    "    print('          ')\n",
    "    print('==========================================================')\n",
    "    print('          ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1a1b0c",
   "metadata": {},
   "source": [
    "# Jenis 4. Logarithmic Trf Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5508c936",
   "metadata": {},
   "source": [
    "## 1A. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68dd6040",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l = df_log.drop(columns=['Reached.on.Time_Y.N'])\n",
    "y_l = df_log[['Reached.on.Time_Y.N']]\n",
    "\n",
    "X_l_train, X_l_test, y_l_train, y_l_test = train_test_split(X_l, y_l, test_size=0.3, random_state=42,stratify=y_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ba6e20",
   "metadata": {},
   "source": [
    "## 1B. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b157991",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    # \"Support Vector Machine (RBF Kernel)\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"XGboost\": XGBClassifier(random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5818760a",
   "metadata": {},
   "source": [
    "## 1C. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1deff92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors\n",
      "          \n",
      "Score:  0.6144\n",
      "Accuracy (Test Set):  0.6144\n",
      "Precision (Test Set):  0.6836\n",
      "Recall (Test Set):  0.6709\n",
      "F1-Score (Test Set):  0.6772\n",
      "roc-auc (test-proba):  0.6533\n",
      "roc-auc (train-proba):  0.8347\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "Decision Tree\n",
      "          \n",
      "Score:  0.651\n",
      "Accuracy (Test Set):  0.651\n",
      "Precision (Test Set):  0.7082\n",
      "Recall (Test Set):  0.7163\n",
      "F1-Score (Test Set):  0.7122\n",
      "roc-auc (test-proba):  0.6341\n",
      "roc-auc (train-proba):  1.0\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "Random Forest\n",
      "          \n",
      "Score:  0.6576\n",
      "Accuracy (Test Set):  0.6576\n",
      "Precision (Test Set):  0.753\n",
      "Recall (Test Set):  0.6429\n",
      "F1-Score (Test Set):  0.6936\n",
      "roc-auc (test-proba):  0.7361\n",
      "roc-auc (train-proba):  1.0\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "Gradient Boosting\n",
      "          \n",
      "Score:  0.6761\n",
      "Accuracy (Test Set):  0.6761\n",
      "Precision (Test Set):  0.8512\n",
      "Recall (Test Set):  0.5608\n",
      "F1-Score (Test Set):  0.6761\n",
      "roc-auc (test-proba):  0.7324\n",
      "roc-auc (train-proba):  0.8406\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "Gaussian Naive Bayes\n",
      "          \n",
      "Score:  0.6705\n",
      "Accuracy (Test Set):  0.6705\n",
      "Precision (Test Set):  0.8062\n",
      "Recall (Test Set):  0.5969\n",
      "F1-Score (Test Set):  0.686\n",
      "roc-auc (test-proba):  0.7351\n",
      "roc-auc (train-proba):  0.7437\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "AdaBoost\n",
      "          \n",
      "Score:  0.6741\n",
      "Accuracy (Test Set):  0.6741\n",
      "Precision (Test Set):  0.8301\n",
      "Recall (Test Set):  0.5778\n",
      "F1-Score (Test Set):  0.6813\n",
      "roc-auc (test-proba):  0.7377\n",
      "roc-auc (train-proba):  0.7907\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "XGboost\n",
      "          \n",
      "Score:  0.6428\n",
      "Accuracy (Test Set):  0.6428\n",
      "Precision (Test Set):  0.7257\n",
      "Recall (Test Set):  0.655\n",
      "F1-Score (Test Set):  0.6885\n",
      "roc-auc (test-proba):  0.7318\n",
      "roc-auc (train-proba):  0.9832\n",
      "          \n",
      "==========================================================\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(X_l_train, y_l_train)\n",
    "    y_l_pred = model.predict(X_l_test)\n",
    "    y_l_pred_proba = model.predict_proba(X_l_test)\n",
    "    y_l_pred_train = model.predict(X_l_train)\n",
    "    y_l_pred_train_proba = model.predict_proba(X_l_train)\n",
    "    print(name)\n",
    "    print('          ')\n",
    "    model_eval(model, y_l_pred, X_l_train, y_l_train, X_l_test, y_l_test, y_l_pred_proba, y_l_pred_train_proba)\n",
    "    print('          ')\n",
    "    print('==========================================================')\n",
    "    print('          ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4e331e",
   "metadata": {},
   "source": [
    "## 1D. Apakah Model Sudah Best-fit?\n",
    "Belum bestfit, score penting dapat ditingkatkan menggunakan hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40d0952",
   "metadata": {},
   "source": [
    "## 1E. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b22e637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression Hyperparameter Tuning\n",
    "hyperparameterlr = {'penalty' : ['l1', 'l2'],\n",
    "                    'C' : [0.0001, 0.001, 0.1, 0.02, 0.03, 0.01], \n",
    "                    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "                   }\n",
    "\n",
    "# DesicionTree Hyperparameter Tuning\n",
    "hyperparameterdt = {'max_depth' : [int(x) for x in np.linspace(1, 100, num = 30)], # Maximum number of levels in tree, \n",
    "                    'min_samples_split' : [2, 5, 10, 100], # Minimum number of samples required to split a node, \n",
    "                    'min_samples_leaf' : [1, 2, 4, 10, 20, 50], # Minimum number of samples required at each leaf node,\n",
    "                    'max_features' : ['auto', 'sqrt','log2'] # Number of features to consider at every split\n",
    "                    }\n",
    "\n",
    "# RandomForest Hyperparameter Tuning\n",
    "hyperparameterrf = {'n_estimators' : [int(x) for x in np.linspace(1, 10, num = 10)],\n",
    "                    'max_depth' : [int(x) for x in np.linspace(1, 10, num = 3)], # Maximum number of levels in tree\n",
    "                    'min_samples_split' : [int(x) for x in np.linspace(1, 40, num = 30)], # Minimum number of samples required to split a node\n",
    "                    'min_samples_leaf' : [int(x) for x in np.linspace(1, 20, num = 30)], # Minimum number of samples required at each leaf node\n",
    "                    'max_features' : ['auto', 'sqrt','log2'], # Number of features to consider at every split\n",
    "                    'criterion' : ['gini', 'entropy']\n",
    "                   }\n",
    "\n",
    "# K-Nearest Neighbors Hyperparameter Tuning]\n",
    "hyperparameterkn = {'leaf_size' : list(range(1,50)),\n",
    "                    'n_neighbors' : list(range(1,30)),\n",
    "                    'p' : [1,2]\n",
    "                   }\n",
    "\n",
    "# Gaussian Naive Bayes Hyperparameter Tuning\n",
    "hyperparameterNB = {'var_smoothing' : [int(x) for x in np.linspace(0,100, num=10)] \n",
    "                   }\n",
    "\n",
    "# Gradient Boosting hyperparameter Tuning\n",
    "hyperparametergb = {'n_estimators' : [2,6,8,10],\n",
    "                    'max_depth' : [int(x) for x in np.linspace(1, 100, num = 5)], # Maximum number of levels in tree\n",
    "                    'learning_rate' : [0.01,0.1,1,10]\n",
    "                   }\n",
    "\n",
    "# # Adaboost hyperparameter Tuning\n",
    "# n_estimators = [int(x) for x in np.linspace(100, 2000, 1000)],\n",
    "# learning_rate = [float(x) for x in np.linspace(0.001, 0.1, 100)],\n",
    "# algorithm = ['SAMME', 'SAMME.R']\n",
    "# hyperparameterab = dict(\n",
    "#                         n_estimators = n_estimators,\n",
    "#                         algorithm = algorithm, \n",
    "#                         learning_rate = learning_rate \n",
    "#                         )\n",
    "\n",
    "# XGBoost hyperparameter Tuning\n",
    "hyperparameterxgb = {'max_depth' : [int(x) for x in np.linspace(10, 50, 10)],\n",
    "                    'min_child_weight' : [int(x) for x in np.linspace(1, 10, 11)],\n",
    "                    'gamma' : [float(x) for x in np.linspace(0, 1, 11)],\n",
    "                    'tree_method' : ['auto', 'exact', 'approx', 'hist'],\n",
    "                    'colsample_bytree' : [float(x) for x in np.linspace(0, 1, 11)],\n",
    "                    'learning_rate' : [float(x) for x in np.linspace(0, 1, 100)],\n",
    "                    'reg_lambda' : [float(x) for x in np.linspace(0, 1, 11)],\n",
    "                    'reg_alpha' : [float(x) for x in np.linspace(0, 1, 11)],\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f04ba164",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"K-Nearest Neighbors tuned\": RandomizedSearchCV(KNeighborsClassifier(), hyperparameterkn, cv=5, scoring='roc_auc'),\n",
    "    \"Decision Tree tuned\": RandomizedSearchCV(DecisionTreeClassifier(random_state = 42), hyperparameterdt, cv=5, scoring='roc_auc'),\n",
    "    # \"Support Vector Machine (RBF Kernel)\": SVC(),\n",
    "    \"Random Forest tuned\": RandomizedSearchCV(RandomForestClassifier(random_state = 42), hyperparameterrf, cv=5, scoring='roc_auc'),\n",
    "    \"Gradient Boosting tuned\": RandomizedSearchCV(GradientBoostingClassifier(random_state = 42), hyperparametergb, cv=5, scoring='roc_auc'),\n",
    "    \"Gaussian Naive Bayes tuned\": RandomizedSearchCV(GaussianNB(), hyperparameterNB, cv=5, verbose=1, scoring='roc_auc'),\n",
    "    # \"AdaBoost tuned\": RandomizedSearchCV(AdaBoostClassifier(random_state = 42), hyperparametergb, cv=5, scoring='roc_auc'),\n",
    "    \"XGboost tuned\": RandomizedSearchCV(XGBClassifier(random_state = 42), hyperparametergb, cv=5, scoring='roc_auc')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae765d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors tuned\n",
      "          \n",
      "Score:  0.6949\n",
      "Accuracy (Test Set):  0.621\n",
      "Precision (Test Set):  0.6747\n",
      "Recall (Test Set):  0.7169\n",
      "F1-Score (Test Set):  0.6952\n",
      "roc-auc (test-proba):  0.6949\n",
      "roc-auc (train-proba):  0.766\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "Decision Tree tuned\n",
      "          \n",
      "Score:  0.7271\n",
      "Accuracy (Test Set):  0.6464\n",
      "Precision (Test Set):  0.7289\n",
      "Recall (Test Set):  0.6583\n",
      "F1-Score (Test Set):  0.6918\n",
      "roc-auc (test-proba):  0.7271\n",
      "roc-auc (train-proba):  0.8396\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "Random Forest tuned\n",
      "          \n",
      "Score:  0.7269\n",
      "Accuracy (Test Set):  0.6633\n",
      "Precision (Test Set):  0.8292\n",
      "Recall (Test Set):  0.5559\n",
      "F1-Score (Test Set):  0.6656\n",
      "roc-auc (test-proba):  0.7269\n",
      "roc-auc (train-proba):  0.8564\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "Gradient Boosting tuned\n",
      "          \n",
      "Score:  0.7362\n",
      "Accuracy (Test Set):  0.6718\n",
      "Precision (Test Set):  0.8925\n",
      "Recall (Test Set):  0.5181\n",
      "F1-Score (Test Set):  0.6556\n",
      "roc-auc (test-proba):  0.7362\n",
      "roc-auc (train-proba):  0.7638\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Gaussian Naive Bayes tuned\n",
      "          \n",
      "Score:  0.7352\n",
      "Accuracy (Test Set):  0.6705\n",
      "Precision (Test Set):  0.8062\n",
      "Recall (Test Set):  0.5969\n",
      "F1-Score (Test Set):  0.686\n",
      "roc-auc (test-proba):  0.7352\n",
      "roc-auc (train-proba):  0.7437\n",
      "          \n",
      "==========================================================\n",
      "          \n",
      "XGboost tuned\n",
      "          \n",
      "Score:  0.7423\n",
      "Accuracy (Test Set):  0.6715\n",
      "Precision (Test Set):  0.8924\n",
      "Recall (Test Set):  0.5175\n",
      "F1-Score (Test Set):  0.6551\n",
      "roc-auc (test-proba):  0.7423\n",
      "roc-auc (train-proba):  0.7571\n",
      "          \n",
      "==========================================================\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(X_l_train, y_l_train)\n",
    "    y_l_pred = model.predict(X_l_test)\n",
    "    y_l_pred_proba = model.predict_proba(X_l_test)\n",
    "    y_l_pred_train = model.predict(X_l_train)\n",
    "    y_l_pred_train_proba = model.predict_proba(X_l_train)\n",
    "    print(name)\n",
    "    print('          ')\n",
    "    model_eval(model, y_l_pred, X_l_train, y_l_train, X_l_test, y_l_test, y_l_pred_proba, y_l_pred_train_proba)\n",
    "    print('          ')\n",
    "    print('==========================================================')\n",
    "    print('          ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1cc4aa",
   "metadata": {},
   "source": [
    "# [Best Model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027e4f6e",
   "metadata": {},
   "source": [
    "Dari sekian model yang dicoba di atas, best model adalah model Logistic Regression. Kedua cara preprocessing tidak terlihat terlalu memengaruhi score dari model.\n",
    "\n",
    "Kami memprioritaskan:\n",
    "1. AUC score yang tinggi dan tidak memiliki perbedaan jauh di antara AUC-train dan AUC-test\n",
    "2. AUC-train < 1.00\n",
    "3. Recall score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1ec920",
   "metadata": {},
   "source": [
    "Model Logistic Regression dengan Transformasi Logarithmic:\n",
    "- Score:  0.73\n",
    "- Accuracy (Test Set):  0.6467\n",
    "- Precision (Test Set):  0.6933\n",
    "- Recall (Test Set):  0.7426\n",
    "- F1-Score (Test Set):  0.7171\n",
    "- roc-auc (test-proba):  0.73\n",
    "- roc-auc (train-proba):  0.7373\n",
    "\n",
    "Best Parameters:\n",
    "- Best penalty : l2\n",
    "- Best C : 0.1\n",
    "- Best solver : liblinear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e52281",
   "metadata": {},
   "source": [
    "# [Soal Nomor 2] Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140815d6",
   "metadata": {},
   "source": [
    "## 2A. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "745b3961",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_llr = LogisticRegression(penalty='l2', C=0.1, solver='liblinear',random_state=42)\n",
    "best_llr.fit(X_llr_train, y_llr_train)\n",
    "\n",
    "importance_llr = best_llr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4479cc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Product_importance</td>\n",
       "      <td>0.138431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gender</td>\n",
       "      <td>0.103564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prior_purchase_std</td>\n",
       "      <td>-0.180974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>product_cost_norm</td>\n",
       "      <td>1.409413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>discount_norm</td>\n",
       "      <td>2.610242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weight_norm</td>\n",
       "      <td>-0.210436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Warehouse_block_B</td>\n",
       "      <td>0.172538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Warehouse_block_C</td>\n",
       "      <td>0.194155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Warehouse_block_D</td>\n",
       "      <td>0.158731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Warehouse_block_F</td>\n",
       "      <td>0.134506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mode_of_Shipment_Road</td>\n",
       "      <td>0.017114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mode_of_Shipment_Ship</td>\n",
       "      <td>0.056444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cost_Per_Weight</td>\n",
       "      <td>-0.788251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cost_After_Disc</td>\n",
       "      <td>-0.010331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Weight_level</td>\n",
       "      <td>-0.900502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Feature     Score\n",
       "0      Product_importance  0.138431\n",
       "1                  Gender  0.103564\n",
       "2      prior_purchase_std -0.180974\n",
       "3       product_cost_norm  1.409413\n",
       "4           discount_norm  2.610242\n",
       "5             weight_norm -0.210436\n",
       "6       Warehouse_block_B  0.172538\n",
       "7       Warehouse_block_C  0.194155\n",
       "8       Warehouse_block_D  0.158731\n",
       "9       Warehouse_block_F  0.134506\n",
       "10  Mode_of_Shipment_Road  0.017114\n",
       "11  Mode_of_Shipment_Ship  0.056444\n",
       "12        Cost_Per_Weight -0.788251\n",
       "13        Cost_After_Disc -0.010331\n",
       "14           Weight_level -0.900502"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize feature importance\n",
    "feats_i = []\n",
    "feats = []\n",
    "feats_s = []\n",
    "for i,v in enumerate(importance_llr):\n",
    "    feats_i.append(i+1)\n",
    "    feats.append(X_llr_train.columns[i])\n",
    "    feats_s.append(v)\n",
    "    \n",
    "feat_imp = pd.DataFrame({\n",
    "#    '#': feats_i,\n",
    "    'Feature': feats,\n",
    "    'Score' : feats_s\n",
    "})\n",
    "#\tprint('Feature',i,':', X_llr_train.columns[i],'\\nScore:',v,'\\n------------------')\n",
    "\n",
    "feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e3d876d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance_llr))], importance_llr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6f6dcc",
   "metadata": {},
   "source": [
    "Dari grafik di atas, fitur `discount_norm` dan `product_cost_norm` sangat memengaruhi keterlambatan produk sampai dan `Weight_level` dan `Cost_Per_Weight` sangat memengaruhi ketepatan waktu produk sampai.\n",
    "\n",
    "Semakin tinggi diskon yang ditawarkan ternyata semakin tinggi juga potensi keterlambatan, asumsinya adalah perusahaan mengabaikan service kepada customer karena sudah diberikan diskon."
   ]
  },
  {
   "attachments": {
    "424b93ed-b36e-42c5-b102-b839033dfbeb.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "d6902b55",
   "metadata": {},
   "source": [
    "## 2B. Feature Selection![download.png](attachment:424b93ed-b36e-42c5-b102-b839033dfbeb.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "619cf7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_llr_2 = df_log_lr[['discount_norm','product_cost_norm','Weight_level','Cost_Per_Weight']]\n",
    "y_llr_2 = df_log_lr[['Reached.on.Time_Y.N']]\n",
    "\n",
    "X_llr_2_train, X_llr_2_test, y_llr_2_train, y_llr_2_test = train_test_split(X_llr_2, y_llr_2, test_size=0.3, random_state=42,stratify=y_llr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c3a2f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.6349\n",
      "Accuracy (Test Set):  0.6349\n",
      "Precision (Test Set):  0.676\n",
      "Recall (Test Set):  0.7574\n",
      "F1-Score (Test Set):  0.7144\n",
      "roc-auc (test-proba):  0.7294\n",
      "roc-auc (train-proba):  0.7322\n"
     ]
    }
   ],
   "source": [
    "best_llr = LogisticRegression(penalty='l2', C=0.1, solver='liblinear',random_state=42)\n",
    "best_llr.fit(X_llr_2_train, y_llr_2_train)\n",
    "\n",
    "y_llr_2_pred = best_llr.predict(X_llr_2_test)\n",
    "y_llr_2_pred_proba = best_llr.predict_proba(X_llr_2_test)\n",
    "y_llr_2_pred_train = best_llr.predict(X_llr_2_train)\n",
    "y_llr_2_pred_train_proba = best_llr.predict_proba(X_llr_2_train)\n",
    "\n",
    "model_eval(best_llr, y_llr_2_pred, X_llr_2_train, y_llr_2_train, X_llr_2_test, y_llr_2_test, y_llr_2_pred_proba, y_llr_2_pred_train_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af959c34",
   "metadata": {},
   "source": [
    "Setelah melakukan iterasi model sesuai dengan best parameters, nilai AUC-test turun dari 73% menjadi 72.94%, AUC-train turun dari 73.73% menjadi 73.22%, dan nilai Recall naik dari 74.26% ke 75.74%.\n",
    "\n",
    "Walaupun Feature Selection hanya menggunakan 4 fitur, penurunan nilai kedua score AUC tidak terlalu signifikan dan peningkatan nilai Recall cukup besar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7b0f07",
   "metadata": {},
   "source": [
    "# [Soal Nomor 3] Git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d896aa2c",
   "metadata": {},
   "source": [
    "Link Github:\n",
    "https://github.com/refaniefs/rakamin/tree/main/final-project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295ada2f",
   "metadata": {},
   "source": [
    "# SELESAI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
